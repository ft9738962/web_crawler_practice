{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本次练习对象为喜马拉雅平台《晓说》第27期评论爬虫\n",
    "\n",
    "网址https://www.ximalaya.com/renwen/7651313/54212132/\n",
    "\n",
    "评论共34页，从p1至p34，保存格式为：\n",
    "\n",
    "|编号|评论人|评论时间|评论内容|回复评论编号|点赞数|\n",
    "|:-:|:-:|:-:|:-:|:-:|:-:|\n",
    "|1|用户A|1年前|不错！|-|2|\n",
    "|2|用户B|8月前|喜欢听|001|0|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, time, json, emoji\n",
    "from bs4 import BeautifulSoup\n",
    "from requests.exceptions import RequestException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = get_one_page('https://www.ximalaya.com/renwen/7651313/54212132/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_page(url):\n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 \\\n",
    "            (KHTML, like Gecko) Chrome/63.0.3239.26 Safari/537.36 Core/1.63.6788.400 \\\n",
    "            QQBrowser/10.3.2727.400'\n",
    "        }\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            return response.text\n",
    "        return None\n",
    "    except RequestException:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str,\n",
       " str]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[type(i.get_text()) for i in soup.find_all(class_='comment-body')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling Start...\n",
      "5 pages have been crawled...\n",
      "10 pages have been crawled...\n",
      "15 pages have been crawled...\n",
      "20 pages have been crawled...\n",
      "25 pages have been crawled...\n",
      "30 pages have been crawled...\n",
      "Crawling Complete\n"
     ]
    }
   ],
   "source": [
    "def get_one_page(url):\n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 \\\n",
    "            (KHTML, like Gecko) Chrome/63.0.3239.26 Safari/537.36 Core/1.63.6788.400 \\\n",
    "            QQBrowser/10.3.2727.400'\n",
    "        }\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            return response.text\n",
    "        return None\n",
    "    except RequestException:\n",
    "        return None\n",
    "\n",
    "def parse_one_page(html):\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    users = [a.find(class_='orange-1').get_text() for a in soup.find_all(class_='comment-head')]  # find第一个用户名为\n",
    "    time = [i.get_text() for i in soup.find_all(class_='comment-time')]\n",
    "    comments = [emoji.demojize(i.get_text()) for i in soup.find_all(class_='comment-body')]\n",
    "    #upvotes = [i.string for i in soup.find_all(i)]\n",
    "    return users, time, comments\n",
    "\n",
    "def write_2_file(html):\n",
    "    users, time, comments = parse_one_page(html)\n",
    "    with open('comments.csv', 'a') as f:\n",
    "        for i in range(len(users)):\n",
    "            #print(u, t ,c)\n",
    "            f.write(f'{users[i]},')\n",
    "            f.write(f'{time[i]},')\n",
    "            try:\n",
    "                f.write(f'{comments[i]}\\n')\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "def main(page):\n",
    "    url = 'https://www.ximalaya.com/renwen/7651313/54212132/p'+str(page)\n",
    "    write_2_file(get_one_page(url))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    with open('comments.csv', 'a') as f:\n",
    "        f.write('评论人, 评论时间, 评论内容\\n')\n",
    "    \n",
    "    print('Crawling Start...')\n",
    "    for i in range(1, 35):\n",
    "            main(page=i)\n",
    "            if i % 5 == 0:\n",
    "                print(f'{i} pages have been crawled...')\n",
    "            time.sleep(1)\n",
    "    print('Crawling Complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 小结\n",
    "#### 收获\n",
    "1. 使用BS编写了基本的爬虫\n",
    "2. 了解到在BS中应该使用get_text()提取文本内容，获得str格式内容，而不是使用string来提取内容，其格式为element.string，容易在写入时出现问题\n",
    "3. 用户使用emoji表情容易被文本误写入，可以配合emoji库来清理\n",
    "\n",
    "#### 待改进\n",
    "1. 之前计划的爬取内容有部分因为太繁琐（点赞数），回复对象等未能爬取\n",
    "2. 还有部分文本报错无法爬取（待确认问题是什么）\n",
    "3. 部分回复使用JS隐藏，只能爬取html显示的部分"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
